"""
Autonomous Analysis: fast_food_consumption_health_impact_dataset
Generated: 2025-12-28 15:30:20
Task Type: classification

This code was automatically generated by the Autonomous Data Science Agent.
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import json
import warnings
warnings.filterwarnings("ignore")

# Setup
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")

# Configuration
DATASET_PATH = "/workspace/user_input_files/fast_food_consumption_health_impact_dataset.csv"
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
# Use current directory since output folder is already created
OUTPUT_FOLDER = "."

# Create subdirectories for outputs
import os
os.makedirs("visualizations", exist_ok=True)
os.makedirs("data", exist_ok=True)

# Load data
print("="*80)
print("AUTONOMOUS DATA ANALYSIS")
print("="*80)
print(f"Dataset: {{DATASET_PATH}}")
print(f"Output: {{OUTPUT_FOLDER}}")
print()

df = pd.read_csv(DATASET_PATH)
print(f"Dataset loaded: {df.shape[0]} rows x {df.shape[1]} columns")
print()

# ============================================================
# 1. BASIC STATISTICS
# ============================================================
print("="*80)
print("1. BASIC STATISTICS")
print("="*80)

# Save basic stats
basic_stats = {{
    "shape": list(df.shape),
    "columns": list(df.columns),
    "dtypes": df.dtypes.astype(str).to_dict(),
    "missing_values": df.isnull().sum().to_dict()
}}

with open(f"{{OUTPUT_FOLDER}}/data/basic_statistics.json", "w") as f:
    json.dump(basic_stats, f, indent=2, default=str)

print(df.describe().round(2))
print()
print("Missing values:")
for col in df.columns:
    missing = df[col].isnull().sum()
    if missing > 0:
        print(f"  {{col}}: {{missing}}")
print()

# ============================================================
# 2. DISTRIBUTION ANALYSIS
# ============================================================
print("="*80)
print("2. DISTRIBUTION ANALYSIS")
print("="*80)

# Distribution plots
numeric_cols = ['Age', 'Fast_Food_Meals_Per_Week', 'Average_Daily_Calories', 'BMI', 'Physical_Activity_Hours_Per_Week', 'Sleep_Hours_Per_Day', 'Energy_Level_Score', 'Doctor_Visits_Per_Year', 'Overall_Health_Score']
categorical_cols = ['Gender', 'Digestive_Issues']

n_numeric = len(numeric_cols)
n_rows = (n_numeric + 2) // 3
fig, axes = plt.subplots(n_rows, 3, figsize=(15, 4*n_rows))
axes = axes.flatten() if n_rows > 1 else [axes[i] if i < len(axes) else None for i in range(3)]

for i, col in enumerate(numeric_cols):
    ax = axes[i] if i < len(axes) else None
    if ax is not None:
        df[col].hist(bins=30, ax=ax, edgecolor="black", alpha=0.7)
        ax.set_title(f"{{col}} Distribution")
        ax.set_xlabel(col)
        ax.set_ylabel("Frequency")
        mean_val = df[col].mean()
        median_val = df[col].median()
        ax.axvline(mean_val, color="red", linestyle="--", label=f"Mean: {{mean_val:.2f}}")
        ax.axvline(median_val, color="green", linestyle="--", label=f"Median: {{median_val:.2f}}")
        ax.legend(fontsize=8)

for i in range(len(numeric_cols), len(axes)):
    if axes[i] is not None:
        axes[i].axis("off")

plt.tight_layout()
plt.savefig(f"{{OUTPUT_FOLDER}}/visualizations/distributions.png", dpi=150, bbox_inches="tight")
plt.close()
print(f"Saved: visualizations/distributions.png")

# Categorical distributions
if categorical_cols:
    n_cats = len(categorical_cols)
    fig, axes = plt.subplots(1, n_cats, figsize=(5*n_cats, 4))
    axes = [axes] if n_cats == 1 else axes

    for i, col in enumerate(categorical_cols):
        counts = df[col].value_counts()
        axes[i].pie(counts, labels=counts.index, autopct="%1.1f%%", startangle=90)
        axes[i].set_title(f"{{col}} Distribution")

    plt.tight_layout()
plt.savefig(f"{{OUTPUT_FOLDER}}/visualizations/categorical_distributions.png", dpi=150, bbox_inches="tight")
plt.close()
print(f"Saved: visualizations/categorical_distributions.png")

# ============================================================
# 3. CORRELATION ANALYSIS
# ============================================================
print("="*80)
print("3. CORRELATION ANALYSIS")
print("="*80)

if len(numeric_cols) > 1:
    numeric_data = df[numeric_cols]
    correlation_matrix = numeric_data.corr()

    # Correlation heatmap
    fig, ax = plt.subplots(figsize=(12, 10))
    mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))
    sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap="RdYlBu_r",
                center=0, fmt=".2f", square=True, linewidths=0.5, ax=ax,
                cbar_kws={{"shrink": 0.8}})
    ax.set_title("Correlation Heatmap", fontsize=14, fontweight="bold")
    plt.tight_layout()
    plt.savefig(f"{{OUTPUT_FOLDER}}/visualizations/correlation_heatmap.png", dpi=150, bbox_inches="tight")
    plt.close()
    print(f"Saved: visualizations/correlation_heatmap.png")

    # Top correlations
    correlations = []
    for i in range(len(correlation_matrix.columns)):
        for j in range(i):
            corr = correlation_matrix.iloc[i, j]
            col1 = correlation_matrix.columns[i]
            col2 = correlation_matrix.columns[j]
            correlations.append({{"pair": f"{{col1}} vs {{col2}}", "correlation": corr}})

    correlations.sort(key=lambda x: abs(x["correlation"]), reverse=True)

    print()
    print("Top 10 Correlations:")
    for item in correlations[:10]:
        sign = "+" if item["correlation"] > 0 else "-"
        corr_val = abs(item["correlation"])
        print(f"  {{item["pair"]}}: {{sign}}{{corr_val:.3f}}")

    with open(f"{{OUTPUT_FOLDER}}/data/correlations.json", "w") as f:
        json.dump(correlations, f, indent=2)

# ============================================================
# 4. TARGET ANALYSIS: Overall_Health_Score
# ============================================================
print("="*80)
print(f"4. TARGET ANALYSIS: {target}")
print("="*80)

target = "Overall_Health_Score"

if target in numeric_cols:
    fig, axes = plt.subplots(1, 2, figsize=(14, 5))

    df[target].hist(bins=30, ax=axes[0], edgecolor="black", alpha=0.7, color="steelblue")
    axes[0].set_title(f"{target} Distribution")
    axes[0].set_xlabel(target)
    axes[0].set_ylabel("Frequency")
    axes[0].axvline(df[target].mean(), color="red", linestyle="--", label=f"Mean: {df[target].mean():.2f}")
    axes[0].legend()

    df.boxplot(column=target, ax=axes[1])
    axes[1].set_title(f"{target} Box Plot")

    plt.tight_layout()
    plt.savefig(f"{{OUTPUT_FOLDER}}/visualizations/target_analysis.png", dpi=150, bbox_inches="tight")
    plt.close()
    print(f"Saved: visualizations/target_analysis.png")

elif target in categorical_cols:
    df[target].value_counts().plot(kind="bar", ax=plt.gca(), color="steelblue", edgecolor="black")
    plt.title(f"{target} Distribution")
    plt.xlabel(target)
    plt.ylabel("Count")
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.savefig(f"{{OUTPUT_FOLDER}}/visualizations/target_analysis.png", dpi=150, bbox_inches="tight")
    plt.close()
    print(f"Saved: visualizations/target_analysis.png")

# ============================================================
# 5. KEY RELATIONSHIPS VISUALIZATION
# ============================================================
print("="*80)
print("5. KEY RELATIONSHIPS")
print("="*80)

if len(numeric_cols) >= 2:
    if "correlations" in dir():
        top_pairs = [(c["pair"].split(" vs ")[0], c["pair"].split(" vs ")[1])
                     for c in correlations[:6]]
    else:
        top_pairs = [(numeric_cols[0], col) for col in numeric_cols[1:7]]

    n_pairs = min(len(top_pairs), 6)
    fig, axes = plt.subplots(2, 3, figsize=(15, 10))
    axes = axes.flatten()

    for i in range(n_pairs):
        col1, col2 = top_pairs[i]
        if col1 in df.columns and col2 in df.columns:
            ax = axes[i]
            ax.scatter(df[col1], df[col2], alpha=0.5, s=20, c="steelblue")

            z = np.polyfit(df[col1], df[col2], 1)
            p = np.poly1d(z)
            x_line = np.linspace(df[col1].min(), df[col1].max(), 100)
            ax.plot(x_line, p(x_line), "r--", alpha=0.8, linewidth=2)

            corr_val = df[col1].corr(df[col2])
            ax.set_title(f"{col1} vs {col2}\n(r={corr_val:.3f})")
            ax.set_xlabel(col1)
            ax.set_ylabel(col2)

    plt.tight_layout()
    plt.savefig(f"{{OUTPUT_FOLDER}}/visualizations/key_relationships.png", dpi=150, bbox_inches="tight")
    plt.close()
    print(f"Saved: visualizations/key_relationships.png")

# ============================================================
# 6. GROUP ANALYSIS
# ============================================================
print("="*80)
print("6. GROUP ANALYSIS")
print("="*80)

if categorical_cols:
    for cat_col in categorical_cols[:2]:
        if len(df[cat_col].unique()) <= 10:
            n_nums = min(len(numeric_cols), 4)
            fig, axes = plt.subplots(1, n_nums, figsize=(5*n_nums, 4))
            axes = [axes] if n_nums == 1 else axes

            for i, num_col in enumerate(numeric_cols[:n_nums]):
                df.boxplot(column=num_col, by=cat_col, ax=axes[i])
                axes[i].set_title(f"{num_col} by {cat_col}")
                axes[i].set_xlabel(cat_col)

            plt.suptitle(f"Analysis by {{cat_col}}", fontsize=14, fontweight="bold")
            plt.tight_layout()
            plt.savefig(f"{{OUTPUT_FOLDER}}/visualizations/group_by_{{cat_col}}.png", dpi=150, bbox_inches="tight")
            plt.close()
            print(f"Saved: visualizations/group_by_{{cat_col}}.png")

# ============================================================
# 7. SUMMARY REPORT
# ============================================================
print("="*80)
print("7. GENERATING SUMMARY REPORT")
print("="*80)

# Generate insights
insights = []

for col in numeric_cols[:5]:
    mean_val = df[col].mean()
    std_val = df[col].std()
    insights.append(f"{{col}}: Mean={{mean_val:.2f}}, Std={{std_val:.2f}}")

if "correlations" in dir():
    for item in correlations[:5]:
        if abs(item["correlation"]) > 0.3:
            relationship = "positive" if item["correlation"] > 0 else "negative"
            strength = "strong" if abs(item["correlation"]) > 0.6 else "moderate" if abs(item["correlation"]) > 0.4 else "weak"
            insights.append(f"{{item["pair"]}}: {{strength}} {{relationship}} correlation ({{item["correlation"]:.3f}})")

# Save summary
summary = {{
    "dataset": {
        "name": "fast_food_consumption_health_impact_dataset",
        "rows": int(df.shape[0]),
        "columns": int(df.shape[1]),
        "numeric_columns": len(numeric_cols),
        "categorical_columns": len(categorical_cols)
    },
    "insights": insights
}}

with open(f"{{OUTPUT_FOLDER}}/data/summary_report.json", "w") as f:
    json.dump(summary, f, indent=2, default=str)

# Generate markdown report
report_content = f"""
# Autonomous Analysis Report
## Dataset: fast_food_consumption_health_impact_dataset
Generated: 2025-12-28 15:30:20

## Overview
- **Rows:** {df.shape[0]:,}
- **Columns:** {df.shape[1]}
- **Numeric columns:** {len(numeric_cols)}
- **Categorical columns:** {len(categorical_cols)}

## Key Statistics

### Distribution Statistics

## Key Insights

---
*Generated by Autonomous Data Science Agent*
"""

with open(f"{{OUTPUT_FOLDER}}/ANALYSIS_REPORT.md", "w") as f:
    f.write(report_content)

print(f"Saved: ANALYSIS_REPORT.md")
print(f"Saved: data/summary_report.json")

print()
print("="*80)
print("ANALYSIS COMPLETE!")
print("="*80)
print(f"All outputs saved to: {{OUTPUT_FOLDER}}")